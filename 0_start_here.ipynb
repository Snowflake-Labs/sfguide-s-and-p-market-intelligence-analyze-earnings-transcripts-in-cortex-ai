{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "ltmn66rcg6tzplakzlsu",
   "authorId": "547381728337",
   "authorName": "ADMIN",
   "authorEmail": "mats.stellwall@snowflake.com",
   "sessionId": "4353f8cf-272c-42ff-9823-e9b9bd3b761a",
   "lastEditTime": 1738249029506
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b2912a-e563-47a2-8731-7bba38772e76",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "This notebook is an adpation of the *Questioning the Answers: LLMs enter the Boardroom, Using Gen AI Tools to Harness Alpha from Earnings Calls by S&P Global Market Intelligence's Quantitative Research & Solutions (QRS) Group research*.\n\n# 1. Overview\nEarnings calls play a pivotal role in shaping investor perceptions. The quality of communication between executives and analysts can significantly influence company performance. Efficient Communicators—executives who deliver proactive presentations, anticipate market queries, and provide clear, on-topic answers to analysts’ questions—consistently outperform their peers. Conversely, Total Redirectors—executives who are reactive, fail to address analysts’ key inquiries during presentations, and provide off-topic responses—significantly underperform.\n\nExecutives' ability to anticipate investor concerns and maintain a focused dialogue fosters confidence and strategic communication. In contrast, failing to provide clarity when analysts seek additional information can lead to misalignment and breakdowns in transparency. A long (short) portfolio of Efficient Communicators (Total Redirectors) generates +515bps of annualized alpha.\n\nThis notebook serves as the blueprint for the research detailed in Quantitative Research & Solutions’ recent publication, \"Questioninig the Answers: LLM's enter the Boardroom.\" It analyse executive on-topicness and proactiveness using the analysts questions, executives answers and LLM answers. This research harness alpha using LLM tools, including vector embeddings, vector cosine similarity, and the LLM quesiton answering."
  },
  {
   "cell_type": "markdown",
   "id": "f5a4c140-634d-4a3d-9db3-bf2febbbbafc",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "# 2. Datasets\n\nIn order to run this notebook you need access to the following datasets from the Snowflake Marketplace:\n\n|Name|Description |\n|----|----|\n|[S&P Dow Jones Indices via Xpressfeed](https://app.snowflake.com/marketplace/listing/GZT0Z8P3D9M/s-p-global-market-intelligence-s-p-dow-jones-indices-via-xpressfeed)|\tThe premium index benchmarking data from major index providers allows investors to track and simulate index performance, and are fully integrated and linked within the S&P Global Market Intelligence data ecosystem, so you can focus on your investment strategy. Premium index data available via Xpressfeed covers index returns (prices), as well as licensed index and their index constituent data all in one place.|\n|[ S&P Capital IQ Financials](https://app.snowflake.com/marketplace/listing/GZT0Z8P3D2N/s-p-global-market-intelligence-s-p-capital-iq-financials)|\tS&P Capital IQ Financials provides global standardized financial statement data for over 180,000 companies, including over 95,000 active and inactive public companies, and As Reported data for over 150,000 companies. S&P Capital IQ Standardized Financials allows you to extend the scope of your historical analysis and back-testing models with consistent data from all filings of a company's historical financial periods including press releases, original filings, and all restatements.|\n|[Global Events](https://app.snowflake.com/marketplace/listing/GZT0Z8P3D38/s-p-global-market-intelligence-global-events)|The Global Events dataset provides details on upcoming and past corporate events such as earnings calls, shareholder/analyst meetings, expected earnings release dates and more. With deep history back to 2003, clients can leverage this dataset to derive signals and support trading models across asset classes, trading styles and frequencies. This dataset also helps in research & analysis, risk management & compliance, and trade surveillance workflows.|\n|[GICS®](https://app.snowflake.com/marketplace/listing/GZT0Z8P3D3S/s-p-global-market-intelligence-gics®) |The GICS dataset includes global industry classifications for public companies, both current and historical. Leverage GICS, jointly developed by S&P Global and MSCI, for a complete, consistent set of global sector and industry definitions. GICS has become the standard widely recognized by market participants worldwide. The GICS methodology assigns each public company to a sub-industry and corresponding industry, industry group and sector, according to the definition of its principle business activity. The current GICS sectors include Energy, Materials, Industrials, Consumer Discretionary, Consumer Staples, Health Care, Financials, Information Technology, Communication Services, Utilities, and Real Estate.|\n|[Compustat® Financials](https://app.snowflake.com/marketplace/listing/GZT0Z8P3D2R/s-p-global-market-intelligence-compustat®-financials)\t|Compustat Financials provides standardized North American and global financial statements and market data for over 80,000 active and inactive publicly traded companies that financial professionals have relied on for over 50 years. Compustat allows investment professionals, academic researchers, and industry analysts to combine deep history with robust and consistent data standardization into their research and backtesting to produce valuable insights and generate alpha. With historical data for North America as far back as 1950 and point-in-time snapshots beginning in 1987, Compustat provides you with insight into company financial performance across many different economic cycles not available anywhere else.|"
  },
  {
   "cell_type": "markdown",
   "id": "fa040835-3299-4600-b06f-9a47ff3312f7",
   "metadata": {
    "name": "cell5",
    "collapsed": false
   },
   "source": "# 3. Libraries & User Inputs\nImport libraries required for workflow\n\n## 3.1 Libraries\n\nNeed to add **cachetools** through **packages**"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "codeCollapsed": false,
    "collapsed": false
   },
   "source": "# Import python packages\nimport streamlit as st\n#import pandas as pd\nfrom datetime import datetime\nimport cachetools\n\nfrom snowflake.snowpark import functions as snow_funcs\nfrom snowflake.snowpark import Window\nfrom snowflake.snowpark.types import ArrayType, StringType\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c4187b8f-34a3-402c-8c63-96623f676453",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "## 3.2 User Inputs\n\nThis research invloves the usage of an embedding model and a completion model, the default models were set to \"snowflake-arctic-embed-m\" for embedding and \"llama3.1-8b\" for completion. This user input section gives you the flexibility to chose your own model for the task."
  },
  {
   "cell_type": "code",
   "id": "fe9edb8d-b06e-4394-acd8-ba517c9b98d6",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "collapsed": false
   },
   "outputs": [],
   "source": "snf_embed_text_func = \"SNOWFLAKE.CORTEX.EMBED_TEXT_768\" # Which of the two embedding functions we want to use\n\nembedding_model = \"snowflake-arctic-embed-m\"\ncompletion_model = \"llama3.1-8b\"\n\n# Name of the databse created in the Setup Snowflake step\nsp_llm_qs_location = \"SP_LLM_QS.PUBLIC\"\n\n# Name of the shared database craeted at the \"Request the S&P Global Market Intelligence QuickStart dataset\" step\nsp_qs_share_location = \"XF_SNOWFLAKE_QUICKSTRAT.XPRESSFEED\"",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12093f26-3af9-4808-8693-9a907b471bb9",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "## 3.3 Date Dimension"
  },
  {
   "cell_type": "code",
   "id": "43a2077b-7605-4f4e-8fa9-7651eb1a5c23",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nbeginDate = '2000-01-01' #start of period for analysis\nendDate = '2023-12-31' #end of period for analysis\n\nnbr_of_days = (datetime.strptime(endDate, \"%Y-%m-%d\") - datetime.strptime(beginDate, \"%Y-%m-%d\")).days\n\n\ncalendar_df = (session.generator(snow_funcs.to_date(snow_funcs.dateadd(\"DAY\", snow_funcs.call_function(\"SEQ4\"), snow_funcs.lit(beginDate))).as_(\"Date\"), rowcount=nbr_of_days)\n               .with_columns([\"Year\", \"Month\", \"Day\", \"Quarter\"],\n                                  [snow_funcs.year(snow_funcs.col(\"Date\"))\n                                   , snow_funcs.month(snow_funcs.col(\"Date\"))\n                                   , snow_funcs.dayofyear(snow_funcs.col(\"Date\"))\n                                   , snow_funcs.quarter(snow_funcs.col(\"Date\"))\n                                   , \n                                  ])\n               .with_columns(['FirstDayOfQuarter', 'LastDayOfQuarter']\n                            , [snow_funcs.min(snow_funcs.col('Date')).over(Window.partition_by(snow_funcs.col('year'), snow_funcs.col('quarter')))\n                              ,snow_funcs.last_day(snow_funcs.col('Date'), \"QUARTER\")])\n              )\n\ncalendar_df.create_or_replace_temp_view(f\"{sp_llm_qs_location}.date_dimension\")\ncalendar_df.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6fb673ab-7641-4655-8b90-f7472120011e",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "# 4. Working with the Data: Russell 3000 Transcripts\nIn this section we query all available Russell 3000 constituent transcripts.\n\n## 4.1 Index Data\n### 4.1.1 Russell 3000 Constituents\nIn the cells below we set the date range for the analysis. The Russell constituents list is collected and formatted to show the daily constituents, including their date, GICS sector and calendarYearQuarter."
  },
  {
   "cell_type": "code",
   "id": "2ff3f821-08b3-4a2f-90fb-7b49d4fb98d2",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "df_indexcon = session.sql(f\"\"\"\nselect distinct\nc.companyId, c.companyName\n, s.securityId\n, ic.tradingItemId, i.indexId, i.indexName, ic.constituentId\n, ti.tickerSymbol, e.exchangeSymbol as exchangeSymbol\n, concat(e.exchangeSymbol, ' : ', ti.tickerSymbol) as exchangeTicker\n, to_date(ic.fromDate) as fromDate, to_date(ifnull(ic.toDate,current_date())) as toDate\n\nfrom {sp_qs_share_location}.ciqIndex i\n    join {sp_qs_share_location}.ciqindexConstituent ic on ic.indexId=i.indexId\n    join {sp_qs_share_location}.ciqTradingItem ti on ti.tradingItemId=ic.tradingItemId\n    join {sp_qs_share_location}.ciqExchange e on e.exchangeId=ti.exchangeId\n    join {sp_qs_share_location}.ciqSecurity s on s.securityId=ti.securityId\n    join (select companyId, companyName from {sp_qs_share_location}.ciqCompany c) c on c.companyId=s.companyId\nwhere i.indexId in (\n--2668699 --S&P 500\n--2668861 --S&P 100\n2668795 --Russell 3000\n) \n\n\"\"\")\n\ndf_indexcon.write.save_as_table(f\"{sp_llm_qs_location}.R3000HISTORYTOPRESENT\", mode=\"overwrite\", table_type='transient')\ndf_indexcon.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "02c32c1f-5f69-4056-8a76-c6f5ad2ab989",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "### 4.1.2 Enrich Russell 3000 Constituents with sector and calendar year quarter"
  },
  {
   "cell_type": "code",
   "id": "2d29287e-26a9-4b55-a7f9-9d07bbd0a1fa",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "df_indexcon = session.sql(f\"\"\"\nselect \n    dd.firstDayOfQuarter, dd.lastDayOfQuarter,\n    concat(dd.year, '-', dd.quarter) as calendarYearQuarter,\n    concat(cp.fiscalYear, '-', cp.fiscalQuarter) as fiscalYearQuarter,\n    cpt.periodTypeName, cpt.periodTypeDescription,\n    r.companyId, r.companyName, r.tradingItemId, gs.gicDesc as Sector, gg.gicDesc as SectorGroup, gind.gicDesc as Industry, gsi.gicDesc as subIndustry\nfrom (select * from {sp_llm_qs_location}.DATE_DIMENSION where date = firstDayOfQuarter) dd\n    join {sp_llm_qs_location}.R3000HISTORYTOPRESENT r on dd.date between ifnull(r.fromDate, '1950-01-01') and ifnull(r.toDate, '2050-12-31')\n    join {sp_qs_share_location}.ciqFinPeriod cp on r.companyId = cp.companyId and dd.year = cp.calendarYear and dd.quarter = cp.calendarQuarter\n    join {sp_qs_share_location}.ciqEventPeriodType cpt on cp.periodTypeId = cpt.periodTypeId\n    \n    left join {sp_qs_share_location}.ciqGvkeyIID gi on gi.RELATEDCOMPANYID=r.companyId and gi.objectId=r.tradingItemId and dd.FirstDayOfQuarter between ifnull(gi.symbolStartDate,'1950-01-01') and ifnull(gi.symbolEndDate,'2050-01-01')\n    left join {sp_qs_share_location}.gic_history gic on gic.GVKEY=gi.GVKEY and dd.FirstDayOfQuarter between ifnull(gic.indFrom,'1950-01-01') and ifnull(gic.indthru,'2050-01-01')\n    left join {sp_qs_share_location}.r_giccd gs on gs.giccd=gic.gsector\n    left join {sp_qs_share_location}.r_giccd gg on gg.giccd=gic.ggroup\n    left join {sp_qs_share_location}.r_giccd gind on gind.giccd=gic.gind\n    left join {sp_qs_share_location}.r_giccd gsi on gsi.giccd=gic.gsubind\n\nwhere 1=1\n    and date between '2000-01-01' and '2024-12-31'\n    and cp.periodTypeId = 2 --Fiscal/Calendar Quarter\norder by calendarYearQuarter asc, companyId asc\n\n\"\"\")\n\ndf_indexcon.write.save_as_table(f\"{sp_llm_qs_location}.R3000HISTORYTOPRESENT_SECTORS\", mode=\"overwrite\", table_type='transient')\ndf_indexcon.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8dc5541a-17eb-47a8-a202-689708e95229",
   "metadata": {
    "name": "cell13",
    "collapsed": false
   },
   "source": "## 4.2 Machine Readable Transcripts\n### 4.2.1 Collect TranscriptId"
  },
  {
   "cell_type": "code",
   "id": "cfefac2b-f198-4737-9cd5-dad7f20f1062",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\ndf_transcript = session.sql(f\"\"\"\n                        \nselect * from \n(select \n    ice.*, t.transcriptId, row_number() over (partition by fiscalYearQuarter, tradingItemId, ice.keyDevId order by t.transcriptCreationDateUTC desc) as latestTranscriptforKeyDev_Flag\n    \nfrom\n(select \n    ice.calendarYearQuarter, ice.fiscalYearQuarter, ice.tradingItemId, ice.companyId, ice.companyName, eot.keyDevId, e.headline\n    , e.mostImportantDateUTC, enteredDate, bi.periodEndDate, languageId, keydeveventtypeid\n    , row_number() over (partition by ice.tradingItemId, bi.fiscalYear, bi.fiscalQuarter order by e.lastModifiedDate desc) as latestKeyDev_Flag \n   from {sp_llm_qs_location}.R3000HISTORYTOPRESENT_SECTORS ice \n    join {sp_qs_share_location}.ciqEventToObjectToEventType eot on ice.companyId = eot.objectId and eot.keydeveventtypeid=48\n    join {sp_qs_share_location}.ciqEvent e on eot.keydevid = e.keydevid\n    join {sp_qs_share_location}.ciqEventCallBasicInfo bi on bi.keyDevId=e.KeyDevId and concat(bi.fiscalYear,'-',bi.fiscalQuarter) = ice.fiscalYearQuarter \n    \nwhere bi.languageId in (0, 123) OR bi.languageId IS NULL --English\n) ice\n    left join {sp_qs_share_location}.ciqTranscript t on t.keyDevId=ice.keyDevId\nwhere 1=1 \n    and t.transcriptId is not null\n    and latestKeyDev_Flag = 1)\nwhere latestTranscriptforKeyDev_Flag = 1 \norder by calendarYearQuarter asc, tradingItemId asc\n\n\"\"\")\n\n\ndf_transcript.write.save_as_table(f\"{sp_llm_qs_location}.R3000HISTORYTOPRESENT_Transcript\", mode=\"overwrite\", table_type='transient')\ndf_transcript.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5faadc21-2409-4e23-bb4b-f691a18fcee3",
   "metadata": {
    "name": "cell15",
    "collapsed": false
   },
   "source": "### **4.2.2 Collect TranscriptId Components\nThis query takes about 30 minutes to executive since it is collecting all Russell 3000 transcript components in the history."
  },
  {
   "cell_type": "code",
   "id": "335778ea-4eea-4ea4-a9e1-40bb3abfe59d",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": "\ndf_transcriptComponents = session.sql(f\"\"\"\nselect distinct \n    u.*\n    , speakerTypeName\n    , tp.transcriptPersonName\n    , tp.transcriptPersonId\n    , tp.proId\n    , ct.transcriptComponentTypeId\n    , transcriptComponentTypeName\n    , componentOrder\n    , transcriptComponentId\n    , componentText\n\nfrom\n(select distinct to_date(mostImportantDateUTC) as callDate, to_date(enteredDate) as enteredDate, fiscalYearQuarter\n         , calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId \n         from {sp_llm_qs_location}.R3000HISTORYTOPRESENT_Transcript) u   \n    join {sp_qs_share_location}.ciqTranscriptComponent tc on tc.transcriptId=u.transcriptId\n    join {sp_qs_share_location}.ciqTranscriptComponentType ct on ct.transcriptComponentTypeId=tc.transcriptComponentTypeId\n    join {sp_qs_share_location}.ciqTranscriptPerson tp on tp.transcriptPersonId=tc.transcriptPersonId\n    join {sp_qs_share_location}.ciqTranscriptSpeakerType st on st.speakerTypeId=tp.speakerTypeId\norder by companyId asc, callDate asc, transcriptId asc, componentOrder asc\n\n\"\"\")\n\ndf_transcriptComponents.write.save_as_table(f\"{sp_llm_qs_location}.R3000HISTORYTOPRESENT_TranscriptComponents\", mode=\"overwrite\", table_type='transient')\ndf_transcriptComponents.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e1938e1f-147c-49f9-a609-b58b9ea769b9",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": "### 4.2.3 Coverage Check"
  },
  {
   "cell_type": "code",
   "id": "a21b7952-c2ad-40f4-8b41-dd9f4ed3b1d1",
   "metadata": {
    "language": "sql",
    "name": "cell19",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "select calendarYearQuarter, count(distinct transcriptId) \nfrom {{sp_llm_qs_location}}.R3000HISTORYTOPRESENT_TRANSCRIPTCOMPONENTS \ngroup by calendarYearQuarter \norder by calendarYearQuarter",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "46d68789-dc5f-4bb6-ba5f-dbe16efe1546",
   "metadata": {
    "name": "cell20",
    "collapsed": false
   },
   "source": "# 5. Working with the Data: Sentence Tokenization\nIn this section we tokenize the prepared remark and the answer components on the sentence level.\n\n## 5.1 Define Sentence Tokenization Function\n\nIn order to run the this step and the following you need to make sure you have created the  NETWORK RULE and  EXTERNAL ACCESS INTEGRATION objects in the **Create Database, Schema And Warehouse To Be Used** step of the quickstart guide."
  },
  {
   "cell_type": "markdown",
   "id": "64ea127e-c7b4-4420-83c2-356c725ace1d",
   "metadata": {
    "name": "cell66",
    "collapsed": false
   },
   "source": "Create a UDF to do the tokenizing."
  },
  {
   "cell_type": "code",
   "id": "4c98252b-160b-4895-80e4-db781831fbe3",
   "metadata": {
    "language": "python",
    "name": "cell21",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "# Using @cachetools.cached ensures that we only download them once\n@cachetools.cached(cache={})\ndef download_files(save_path):\n    import nltk\n    import os\n    \n    os.environ['NLTK_DATA'] = save_path\n\n    # Create the directory if it doesn't exist\n    os.makedirs(save_path, exist_ok=True)\n\n    nltk.download('punkt', download_dir=save_path)\n    nltk.download('punkt_tab', download_dir=save_path) \n                \ndef sentenceTokenize(x):\n    import nltk\n    from nltk.tokenize import sent_tokenize\n\n    # Set the NLTK_DATA environment variable to the desired directory\n    nltk_data_dir = '/tmp/nltk_data'\n    nltk.data.path.append(nltk_data_dir)\n    download_files(nltk_data_dir)\n    \n    return sent_tokenize(x)\n\nsentence_tokenize_udf = snow_funcs.udf(sentenceTokenize\n                                       , return_type = ArrayType(StringType())\n                                       , input_types=[StringType()]\n                                      , packages=['nltk', 'cachetools']\n                                      , external_access_integrations=['NLTK_ACCESS_INTEGRATION'])",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "528b4698-32dd-43d1-a3ab-54479b9920bf",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "## 5.2 Apply Tokenize Sentence Function\nThe code below takes about X minutes to run, since it is sentence tokenizing all historical prepared remarks.\n\n"
  },
  {
   "cell_type": "code",
   "id": "349adeec-304c-4c2f-bafe-caccb6b3fbfc",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = session.table(f\"{sp_llm_qs_location}.R3000HISTORYTOPRESENT_TRANSCRIPTCOMPONENTS\")\n\nfiltered_df = df.filter((snow_funcs.col('transcriptComponentTypeId') == 2) | (snow_funcs.col('transcriptComponentTypeId') == 4))\n\n# Apply the UDF to the DataFrame column\ndf_with_sentences = filtered_df.withColumn(\"sentencesList\", sentence_tokenize_udf(filtered_df[\"componentText\"])).cache_result()\n\n# Explode the sentencesList column and generate the order column\ndf_exploded = (df_with_sentences.select( *[col for col in df_with_sentences.columns if col != \"sentencesList\"]\n                          ,snow_funcs.flatten(snow_funcs.col(\"sentencesList\")).alias(\"SEQ\", \"KEY\", \"PATH\"\n                                                                                     ,  \"sentenceIndex\", \"sentence\", \"THIS\"))\n                .drop(\"SEQ\", \"KEY\", \"PATH\", \"THIS\")\n                .with_column(\"sentence\",snow_funcs.as_char(snow_funcs.col(\"sentence\")))\n              )\n\ndf_exploded.write.save_as_table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_PPP_A_Sentences\", mode=\"overwrite\", table_type='transient')\n\ndf_exploded.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4ed66a3e-f47b-4e7a-92b6-ffd992018e02",
   "metadata": {
    "name": "cell24",
    "collapsed": false
   },
   "source": "# 6. Working with the Data: Retrival Augmented Generation (RAG)\nRetrieval-Augmented Generation (RAG) is a tool that improves LLM consistency by retrieving relevant information before answering a question.\n\nFor this task the LLM needs to be as consistent as possible in its responses to the analysts’ questions as inconsistency will lead to variations in cosine similarity scores and disrupt feature generation downstream.\n\nTo combat this, we designed a Retrieval-Augmented Generation (RAG) engine that chunks the prepared remarks sentence-by-sentence and retrieves the optimal retrieval percentage of sentences most similar to the question. Inconsistency occurs when the LLM is provided with too little (or too much) context, it becomes uninformed (unspecific). The optimal retrieval percentage for consistency is 60%.\n\nIn the cells below, we vector embed all questions, prepared remark sentences and answer sentences using the native databricks-gte-large-en embedding model. Then use the cosine similarity from the (question vs prepared remark sentences) and (question vs answer sentences) to select top 60% most relevant prepared remark and answer sentences to the question from S&P Global Q3 2024 Earnings Call Transcript\n\n## 6.1 S&P Global Q3 2024 Earnings Call Transcript\nSelect and seperate the prepared remarks, questions and answers sections of the S&P Global Q3 2024 Earnings Call"
  },
  {
   "cell_type": "code",
   "id": "164a0ce9-7d9e-40f2-b412-d0058ca3abcd",
   "metadata": {
    "language": "python",
    "name": "cell25",
    "collapsed": false
   },
   "outputs": [],
   "source": "sentences_df = session.table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_PPP_A_Sentences\")\nall_component_df = session.table(f\"{sp_llm_qs_location}.R3000HISTORYTOPRESENT_TRANSCRIPTCOMPONENTS\")\npppSentences = sentences_df.filter(snow_funcs.col('transcriptComponentTypeId') == 2)\nquestions = all_component_df.filter(snow_funcs.col('transcriptComponentTypeId') == 3)\nanswerSentences = sentences_df.filter(snow_funcs.col('transcriptComponentTypeId') == 4)\n\nst.dataframe(pppSentences.limit(5))\nst.dataframe(questions.limit(5))\nst.dataframe(answerSentences.limit(5))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7a7838f1-a7b4-430b-bc2f-e1fd32af6e44",
   "metadata": {
    "name": "cell26",
    "collapsed": false
   },
   "source": "## 6.2 Vector Embedding\n"
  },
  {
   "cell_type": "markdown",
   "id": "b79c3362-1f9f-4a7f-bf74-e308dd01860a",
   "metadata": {
    "name": "cell28",
    "collapsed": false
   },
   "source": "### 6.2.2 Apply Embedding to Transcript Components"
  },
  {
   "cell_type": "code",
   "id": "2b5eb4ac-7f94-48da-91b9-a407f3bdb5ca",
   "metadata": {
    "language": "python",
    "name": "cell29",
    "collapsed": false
   },
   "outputs": [],
   "source": "snf_embed_text = snow_funcs.function(snf_embed_text_func)\n\npppSentences_with_embeddings = pppSentences.withColumn(\"sentenceVec\", snf_embed_text(snow_funcs.lit(embedding_model)\n                                                                                     ,pppSentences[\"sentence\"]))\nquestions_with_embeddings = questions.withColumn(\"componentTextVec\", snf_embed_text(snow_funcs.lit(embedding_model),\n                                                                                    questions[\"componentText\"]))\nanswerSentences_with_embeddings = answerSentences.withColumn(\"sentenceVec\",  snf_embed_text(snow_funcs.lit(embedding_model)\n                                                                                            ,answerSentences[\"sentence\"]))\n\npppSentences_with_embeddings.write.save_as_table(f\"{sp_llm_qs_location}.pppSentencesVec\", mode=\"overwrite\",table_type='transient')\nquestions_with_embeddings.write.save_as_table(f\"{sp_llm_qs_location}.questionsVec\", mode=\"overwrite\", table_type='transient')\nanswerSentences_with_embeddings.write.save_as_table(f\"{sp_llm_qs_location}.answerSentencesVec\", mode=\"overwrite\", table_type='transient')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aca42ae7-a9b7-4713-8c91-ee5148ef347c",
   "metadata": {
    "name": "cell30",
    "collapsed": false
   },
   "source": "# 6.3 Cosine Similarity\nTo determine semantic closeness, we vector-embed the question-and-answer texts and calculate a cosine similarity score between the two vectors.\nFor example, A and B each represent a vector such that:\n\n\n$$\tA = [a_1,a_2,… a_n] $$\n$$\tB = [b_1,b_2,… b_n] $$\n\n\nThe cosine similarity formula between vectors A and B is:\n\n$$\\text{Cosine Similarity} = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\cdot \\|\\mathbf{B}\\|}$$\n\n, where A⋅B is the dot product of the vectors, and |A|⋅|B| is the product of each vector's magnitude.\nThe result ranges from -1 to 1, where:\n\n\t-1: Vectors are opposite.\n\t0: Vectors are unrelated.\n\t1: Vectors are identical."
  },
  {
   "cell_type": "markdown",
   "id": "af1b998b-63db-4a8a-94be-60fa24e3a916",
   "metadata": {
    "name": "cell32",
    "collapsed": false
   },
   "source": "### 6.3.2 Apply Cosine Similarity to Question & Answer Vector Embeddings\nThe cell below creates question and answer pair by collecting all the answer sentences whose componentOrder is between the currentQuestionComponentOrder and the nextQuestionComponentOrder. Then the the consine similarity was applied to the question and answer sentence vector embeddings."
  },
  {
   "cell_type": "code",
   "id": "0d879dde-2ff3-43da-bef4-493cd3621347",
   "metadata": {
    "language": "python",
    "name": "cell33",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(f\"\"\"\n\nwith q as(\n    select \n        callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter,\n        tradingItemId, companyId, companyName, headline, transcriptId,\n        speakerTypeName as questionSpeakerTypeName, transcriptPersonName as questionTranscriptPersonName,\n        transcriptPersonId as questionTranscriptPersonId, proId as questionProId, transcriptComponentTypeId as questionTranscriptComponentTypeId,\n        transcriptComponentId as questionTranscriptComponentId, componentOrder as currentQuestionOrder\n        , lead(componentOrder) over (partition by tradingItemId, transcriptId order by componentOrder) as nextQuestionOrder\n        , componentText as question, componentTextVec as questionVec\n    from {sp_llm_qs_location}.questionsVec\n    where 1=1\n        and transcriptComponentTypeId = 3\n)\nselect \n    q.callDate, q.enteredDate, q.fiscalYearQuarter, q.calendarYearQuarter,\n    q.tradingItemId, q.companyId, q.companyName, q.headline, q.transcriptId,\n    q.questionSpeakerTypeName, q.questionTranscriptPersonName, q.questionTranscriptPersonId, q.questionProId, \n    a.speakerTypeName as answerSpeakerTypeName, a.transcriptPersonName as answerTranscriptPersonName, a.transcriptPersonId as answerTranscriptPersonId, a.proId as answerProId, \n    q.questionTranscriptComponentTypeId, a.transcriptComponentTypeId as answerTranscriptComponentTypeId,\n    q.questionTranscriptComponentId, a.transcriptComponentId as answerTranscriptComponentId,\n    q.currentQuestionOrder, q.nextQuestionOrder, a.componentOrder as answerOrder, a.sentenceIndex as answerSentenceOrder,\n    q.question, a.componentText as answer, a.sentence as answerSentence, q.questionVec, a.sentenceVec as answerSentenceVec\n    , VECTOR_COSINE_SIMILARITY(questionVec, sentenceVec) AS cosine_similarity\nfrom q\n    join {sp_llm_qs_location}.answerSentencesVec a on q.tradingItemId = a.tradingItemId and q.transcriptId = a.transcriptId and a.componentOrder between q.currentQuestionOrder and ifnull(q.nextQuestionOrder, 10000)\norder by q.nextQuestionOrder asc, a.componentOrder asc, a.sentenceIndex asc\n\n\"\"\")\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_qaPairCos\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "87af385b-50e0-4574-b7cf-5ededd2124fb",
   "metadata": {
    "name": "cell34",
    "collapsed": false
   },
   "source": "### 6.3.3 Apply Cosine Similarity to Question & Prepared Remarks Vector Embeddings\nThe cell below pairs all prepared remarks sentences to questions. Then the the consine similarity was applied to the question and prepared remarks sentence vector embeddings."
  },
  {
   "cell_type": "code",
   "id": "05c85911-dbe1-4011-944c-340631482f72",
   "metadata": {
    "language": "python",
    "name": "cell35",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(f\"\"\"\n\nwith q as(\n    select \n        callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter,\n        tradingItemId, companyId, companyName, headline, transcriptId,\n        speakerTypeName as questionSpeakerTypeName, transcriptPersonName as questionTranscriptPersonName,\n        transcriptPersonId as questionTranscriptPersonId, proId as questionProId, transcriptComponentTypeId as questionTranscriptComponentTypeId,\n        transcriptComponentId as questionTranscriptComponentId, componentOrder as currentQuestionOrder, lead(componentOrder) over (partition by tradingItemId, transcriptId order by componentOrder) as nextQuestionOrder, componentText as question, componentTextVec as questionVec\n    from {sp_llm_qs_location}.questionsVec\n    where 1=1\n        and transcriptComponentTypeId = 3\n)\nselect \n    q.*, \n    p.componentOrder as executiveRemarkComponentOrder, p.sentenceIndex as executiveRemarkSentenceOrder,\n    p.componentText as executiveRemark, p.sentence as executiveSentence, p.sentenceVec as executiveVec,\n    VECTOR_COSINE_SIMILARITY(questionVec, p.sentenceVec) as similarity\nfrom q\n    join {sp_llm_qs_location}.pppSentencesVec p on q.tradingItemId = p.tradingItemId and q.transcriptId = p.transcriptId\n\norder by q.nextQuestionOrder asc, p.componentOrder asc, p.sentenceIndex asc\n\n\"\"\")\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_pppQPairCos\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50df1066-d89b-42ad-b7b9-ae16a5e4b409",
   "metadata": {
    "name": "cell36",
    "collapsed": false
   },
   "source": "## 6.4 Top 60% Sentences\nUtilizing the top 60% of prepared remarks identified as generating the most consistent LLM output. For further details on the experiment, please refer to the 'LLM Robustness Check' section in the whitepaper."
  },
  {
   "cell_type": "markdown",
   "id": "c49e6c92-18a2-4b56-aa18-280d3d794e33",
   "metadata": {
    "name": "cell38",
    "collapsed": false
   },
   "source": "### 6.4.2 Concat Top 60% Answer Sentences\nAfter selecting the top 60% most similar answer sentences, we concat the answer sentences on the question level."
  },
  {
   "cell_type": "code",
   "id": "333f44d6-4e82-46a3-8faa-7962e287ea87",
   "metadata": {
    "language": "python",
    "name": "cell39",
    "collapsed": false
   },
   "outputs": [],
   "source": "\ndf = session.sql(f'''\n          \n    with qaSimilarityRank as(\n    select \n        *, \n        ROW_NUMBER() OVER (PARTITION BY tradingItemId, transcriptId, currentQuestionOrder, currentQuestionOrder ORDER BY cosine_similarity desc) AS similarityRank,\n        COUNT(*) OVER (PARTITION BY tradingItemId, transcriptId, currentQuestionOrder, currentQuestionOrder) AS answerSentencesCount \n    from {sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_qaPairCos \n    ), \n    questionWithSixtyPercentAnswers as(\n\n    select \n        *, \n        case \n            when answerSentencesCount = 1 then 1\n            when similarityRank <= answerSentencesCount * 0.67 then 1\n            else 0\n        end as toKeepFlag\n    from qaSimilarityRank\n\n    ),\n    qaPair60 as(\n    select\n        callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName\n        , headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId\n        , questionProId, answerSpeakerTypeName, answerTranscriptPersonName, answerTranscriptPersonId, answerProId\n        , questionTranscriptComponentTypeId, answerTranscriptComponentTypeId, questionTranscriptComponentId\n        , answerTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, answerOrder, question, answer, \n        ARRAY_TO_STRING(ARRAY_AGG(answerSentence), ' ') AS sixtyPercentAnswer\n    from (select * from questionWithSixtyPercentAnswers where toKeepFlag = 1 order by currentQuestionOrder asc, answerOrder asc, answerSentenceOrder asc)\n    group by callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, answerSpeakerTypeName, answerTranscriptPersonName, answerTranscriptPersonId, answerProId, questionTranscriptComponentTypeId, answerTranscriptComponentTypeId, questionTranscriptComponentId, answerTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, answerOrder, question, answer)\n    select \n        callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, answerSpeakerTypeName, answerTranscriptPersonName, answerTranscriptPersonId, answerProId, questionTranscriptComponentTypeId, answerTranscriptComponentTypeId, questionTranscriptComponentId, answerTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, answerOrder, \n        question, answer\n        , SNOWFLAKE.CORTEX.COUNT_TOKENS('{completion_model}',answer) as answerTokenCount\n        , sixtyPercentAnswer\n        , SNOWFLAKE.CORTEX.COUNT_TOKENS('{completion_model}',sixtyPercentAnswer) as sixtyPercentAnswerTokenCount\n    from qaPair60\n    order by currentQuestionOrder asc, answerOrder asc\n              \n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_qaPairTop60\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa16aa95-4ae8-4df0-95a2-d1f9ed43f30f",
   "metadata": {
    "name": "cell40",
    "collapsed": false
   },
   "source": "### 6.4.3 Concat Top 60% Prepared Remarks Sentences\nSimilarly, after selecting the top 60% most similar prepared remarks sentences, we concat the prepared remarks sentences on the question level."
  },
  {
   "cell_type": "code",
   "id": "d9d72152-56ec-48e6-918a-668638042c6b",
   "metadata": {
    "language": "python",
    "name": "cell41",
    "collapsed": false
   },
   "outputs": [],
   "source": "\ndf = session.sql(f'''\n\nwith qaSimilarityRank as(\nselect \n    *, \n    ROW_NUMBER() OVER (PARTITION BY tradingItemId, transcriptId, currentQuestionOrder ORDER BY similarity desc) AS similarityRank,\n    COUNT(*) OVER (PARTITION BY tradingItemId, transcriptId, currentQuestionOrder) AS executiveRemarksSentencesCount\nfrom {sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_pppQPairCos\n),\n\npppQPairTop60 as(\nselect \n    *, \n    case \n        when executiveRemarksSentencesCount = 1 then 1\n        when similarityRank <= executiveRemarksSentencesCount * 0.67 then 1\n        else 0\n    end as toKeepFlag\nfrom qaSimilarityRank),\n\npresenterLevelSixtyPercentPPP as(\nselect\n    callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, questionTranscriptComponentTypeId, questionTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, executiveRemarkComponentOrder, question, executiveRemark, \n    ARRAY_TO_STRING(ARRAY_AGG(executiveSentence), ' ') AS sixtyPercentExecutiveRemark\nfrom (select * from pppQPairTop60 where toKeepFlag = 1 order by currentQuestionOrder asc, executiveRemarkComponentOrder asc, executiveRemarkSentenceOrder asc)\ngroup by callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, questionTranscriptComponentTypeId, questionTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, executiveRemarkComponentOrder, question, executiveRemark\norder by currentQuestionOrder asc,  executiveRemarkComponentOrder asc),\n\npppQPairTop60Concat as(\nselect \n\n    callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, questionTranscriptComponentTypeId, questionTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, question,\n    ARRAY_TO_STRING(ARRAY_AGG(executiveRemark), '\\n\\n') AS questionLevelConcatenatedRawExecutiveRemark,\n    ARRAY_TO_STRING(ARRAY_AGG(sixtyPercentExecutiveRemark), '\\n\\n') AS questionLevelConcatenatedSixtyPercentExecutiveRemark\nfrom (select * from presenterLevelSixtyPercentPPP order by currentQuestionOrder asc,  executiveRemarkComponentOrder asc)\ngroup by callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, questionTranscriptComponentTypeId, questionTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, question\n)\n\nselect \n    callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, questionTranscriptComponentTypeId, questionTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, question,\n    questionLevelConcatenatedRawExecutiveRemark\n    , SNOWFLAKE.CORTEX.COUNT_TOKENS('{completion_model}',questionLevelConcatenatedRawExecutiveRemark) as questionLevelConcatenatedRawExecutiveRemarkTokenCount, questionLevelConcatenatedSixtyPercentExecutiveRemark\n    , SNOWFLAKE.CORTEX.COUNT_TOKENS('{completion_model}',questionLevelConcatenatedSixtyPercentExecutiveRemark) as questionLevelConcatenatedSixtyPercentExecutiveRemarkTokenCount\nfrom pppQPairTop60Concat\norder by currentQuestionOrder asc\n\n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_pppQPairTop60\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2ddb0cf0-76c9-49f2-bab2-41de606b73ce",
   "metadata": {
    "name": "cell42",
    "collapsed": false
   },
   "source": "# 7. Working with the Data: LLM Ready Data\n## 7.1 Using Snowflake Cortex AI\nIn the Snowflake Cortex AI COMPLETE finction, messages are organized into distinct roles—system, user, and assistant—to structure and guide interactions. Each role serves a specific purpose:\n\nSystem: Provides instructions that define the context or behavior of the model. It's like setting the rules or tone for the conversation. Example: \"You are a helpful assistant that answers questions about technology in a concise manner.\"\n\nUser: Represents the input or queries made by the person interacting with the model. These are the prompts or requests that the model responds to. Example: \"What is the purpose of the OpenAI API?\"\n\nAssistant: Reflects the model's response to the user's query, shaped by the system's instructions and the user's input. Example: \"The OpenAI API is designed to enable developers to integrate language models into their applications for tasks like answering questions, generating content, and more.\"\n\nIn our research, executive prepared remarks are labelled as assistant messages, analyst's questions as User messages and executive answers as Assistant messages\n\n### 7.1.1 Construct COMPLETE Assistant Message with QA Pair Snippet"
  },
  {
   "cell_type": "code",
   "id": "ee6e5fe0-f534-4ee3-91fe-ae46983f0e1d",
   "metadata": {
    "language": "python",
    "name": "cell43"
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n\nwith questionWithSixtyPercentAnswersPromptSnippet as (\n\nselect\n    *, \n    OBJECT_CONSTRUCT('role', 'user', 'content', REPLACE(question, '\\r', '')) as questionPromptSnippet,\n    OBJECT_CONSTRUCT('role', 'assistant', 'content', REPLACE(sixtyPercentAnswer, '\\r', '')) as answerPromptSnippet\n    \nfrom {sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_qaPairTop60)\nselect \n    *, ARRAY_CONSTRUCT(questionPromptSnippet, answerPromptSnippet) as questionAnswerPairPromptSnippet \nfrom questionWithSixtyPercentAnswersPromptSnippet\norder by currentQuestionOrder asc, answerOrder asc\n\n''')\n\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_pppQPairTop60AnswerConcat\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3e3b400f-8459-48d4-980f-ab4b99582361",
   "metadata": {
    "name": "cell44",
    "collapsed": false
   },
   "source": "### 7.1.2 Construct OpenAI Assistant Message with Prepared Remarks Snippets"
  },
  {
   "cell_type": "code",
   "id": "36b8a7cf-1219-43b6-8b3d-3360973f8c1e",
   "metadata": {
    "language": "python",
    "name": "cell45"
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n\nselect\n    *,\n    OBJECT_CONSTRUCT('role', 'user', 'content', REPLACE(question, '\\r', '')) as questionPromptSnippet,\n    OBJECT_CONSTRUCT('role', 'assistant', 'content', REPLACE(questionLevelConcatenatedSixtyPercentExecutiveRemark, '\\r', '')) as pppPromptSnippet\nfrom {sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_pppQPairTop60\n\n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_pppQPairTop60PPPConcat\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b8652c71-32ee-4f1e-9972-24f0a47cb5b7",
   "metadata": {
    "name": "cell46",
    "collapsed": false
   },
   "source": "## 7.2 Collect All Messages for OpenAI API\nAll question pairs with prepare remarks and answers come together to form an LLM prompt following the iterative process such that:\n\n1. 'user': 'From the perspective of a top executive, please answer the following question raised by a financial analyst during an earnings conference call. Knowledge cutoff date: '  \n2. 'assistant': 60% prepared remarks  \n3. 'user': question 1  \n4. 'assistant': 60% answer 1  \n5. ...  \n6. ...  \n7. 'user': question n  \n"
  },
  {
   "cell_type": "markdown",
   "id": "38032e69-1d4a-4a21-9a96-c63d5d884a8a",
   "metadata": {
    "name": "cell48",
    "collapsed": false
   },
   "source": "### 7.2.1 LLM Ready Prompt Messages\nIn the dataframe below, the prompt column has all the messages in 1 list. This is the prompt for the LLM."
  },
  {
   "cell_type": "code",
   "id": "9fd9ee2a-5d11-4c02-a8a6-27d28d27f0e6",
   "metadata": {
    "language": "python",
    "name": "cell49"
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n    with pppQPairTop60PPPConcat\n    as\n    (\n    select \n         a.callDate, a.tradingItemId, a.transcriptId, a.headline, \n        a.questionTranscriptPersonName, a.questionTranscriptPersonId, a.questionProId,\n        a.answerTranscriptPersonName, a.answerTranscriptPersonId, a.answerProId,\n        a.questionTranscriptComponentId, a.answerTranscriptComponentId,\n        a.question, a.answer,\n        ARRAY_CONSTRUCT(object_construct('role', 'user', 'content', concat('From the perspective of a top executive, please answer the following question raised by a financial analyst during an earnings conference call. Knowledge cutoff date: ', cast(a.callDate as string)))) as initPrompt,\n       a.questionPromptSnippet,\n       ARRAY_FLATTEN(ARRAY_AGG(a.questionAnswerPairPromptSnippet) OVER (PARTITION BY a.TRANSCRIPTID ORDER BY a.CURRENTQUESTIONORDER \n                                                        ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING)) as concatenatedPredecessors\n     from {sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_pppQPairTop60AnswerConcat a\n    )\n    select a.* \n        , ARRAY_CAT(a.initPrompt, ARRAY_CAT([ppp.pppPromptSnippet], ARRAY_CAT(a.concatenatedPredecessors, [a.questionPromptSnippet]))) as prompt\n    from \n    pppQPairTop60PPPConcat a\n    join {sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_pppQPairTop60PPPConcat as ppp on a.tradingItemId = ppp.tradingItemId and a.transcriptId = ppp.transcriptId and a.questionTranscriptComponentId = ppp.questionTranscriptComponentId\n    order by a.questionTranscriptComponentId asc, a.answerTranscriptComponentId asc\n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_targetLLMReadyPrompt\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c509c9a6-2350-4293-9acc-1fb5c540830e",
   "metadata": {
    "name": "cell50",
    "collapsed": false
   },
   "source": "## 7.3 Collect LLM Response\n"
  },
  {
   "cell_type": "markdown",
   "id": "80eec084-8bba-4537-8c6a-8c86ba0776f0",
   "metadata": {
    "name": "cell52",
    "collapsed": false
   },
   "source": "### 7.3.2 Apply LLM Completion\nWe apply the SNOWFLAKE.CORTEX.COMPLETE function on the prompt column using the model defined by `completion_model`and collect the LLM response."
  },
  {
   "cell_type": "code",
   "id": "ca81a278-6b25-4b8c-9345-93bb753d9aff",
   "metadata": {
    "language": "python",
    "name": "cell53"
   },
   "outputs": [],
   "source": "df = session.sql(f\"\"\"\n    select *,  SNOWFLAKE.CORTEX.COMPLETE('{completion_model}', prompt, {{'temperature': 0}}) as LLMAnswer \n    from {sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_targetLLMReadyPrompt\n          \n\"\"\")\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_targetLLMAnswer\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cde8c8fb-317d-40ec-b17b-a7efc118fc78",
   "metadata": {
    "name": "cell54",
    "collapsed": false
   },
   "source": "# 8. Working with the Data: Factor Construction\n## 8.1 Executive On/Off Topic Factor\nWhen an executive answer is semantically similar (dissimilar) to the analyst’s question, it suggests that the answer uses language and concepts similar to (different from) the analyst question, indicating it is on-topic (off-topic). To determine semantic closeness, we vector-embed the question-and-answer texts and calculate a cosine similarity score between the two vectors.\n\n### 8.1.1 Question vs Executive Answer Cosine Similarity"
  },
  {
   "cell_type": "code",
   "id": "ffc83173-e945-42e1-a8ce-3fe2785bd834",
   "metadata": {
    "language": "python",
    "name": "cell55"
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n\n    with vec as(\n    select *\n        , {snf_embed_text_func}('{embedding_model}', question) as questionVec\n        , {snf_embed_text_func}('{embedding_model}',answer) as answerVec \n    from {sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_targetLLMAnswer\n    )\n    select *, VECTOR_COSINE_SIMILARITY(questionVec, answerVec) as execOnOffTopicFactor from vec \n               \n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_execOnOffTopicFactor\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "38be14f8-7a72-4aab-984c-43aa3e76ff97",
   "metadata": {
    "name": "cell56",
    "collapsed": false
   },
   "source": "### 8.1.2 Transcript Mean Executive On/Off Topic Factor\nCosine similarity scores are averaged at the transcript level. A high (low) Cosine Similarity Score indicates an On (Off) Topic Executive.\n\n"
  },
  {
   "cell_type": "code",
   "id": "9c2f2ed4-20eb-4ff6-a527-05c9362b066f",
   "metadata": {
    "language": "sql",
    "name": "cell57"
   },
   "outputs": [],
   "source": "select avg(execOnOffTopicFactor) as transcriptLevelExecOnOffTopicFactor \nfrom {{sp_llm_qs_location}}.Russell_Constituents_TranscriptComponents_execOnOffTopicFactor\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "916210b3-8d62-4bac-9a1a-13fbc0d08ffc",
   "metadata": {
    "name": "cell58",
    "collapsed": false
   },
   "source": "## 8.2 Executive Proactive/Reactive Factor\n### 8.2.1 Question vs LLM Answer Cosine Similarity\nSince the LLM answers only within the context of information provided in the prepared remarks, a high (low) cosine similarity score indicates that the LLM answers are semantically similar (dissimilar) the questions, reflecting the executives are proactive (reactive)."
  },
  {
   "cell_type": "code",
   "id": "06d679e9-5849-44cd-b73a-595e4a9df160",
   "metadata": {
    "language": "python",
    "name": "cell59"
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n\n    with vec as(\n    select *, {snf_embed_text_func}('{embedding_model}', question) as questionVec, \n    {snf_embed_text_func}('{embedding_model}',LLMAnswer['choices'][0]['messages']::string) as LLMAnswerVec \n        from {sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_targetLLMAnswer\n    )\n    select *, VECTOR_COSINE_SIMILARITY(questionVec, LLMAnswerVec) as execProactiveReactiveFactor from vec \n               \n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.Russell_Constituents_TranscriptComponents_execProactiveReactiveFactor\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5999994a-81e2-428f-ab24-4a5eeb72e150",
   "metadata": {
    "name": "cell60",
    "collapsed": false
   },
   "source": "### 8.2.2 Transcript Mean Executive Proactive/Reactive Factor\nSimilar to the construction of the Executive On/Off Topic factor, both the LLM answers and questions are summarized, vector-embedded and cosine similarity scores are averaged at the transcript level."
  },
  {
   "cell_type": "code",
   "id": "79c48dfb-ca72-41ba-af86-d0f5975d6c48",
   "metadata": {
    "language": "sql",
    "name": "cell61"
   },
   "outputs": [],
   "source": "select avg(execProactiveReactiveFactor) as transcriptLevelexecProactiveReactiveFactor \nfrom {{sp_llm_qs_location}}.Russell_Constituents_TranscriptComponents_execProactiveReactiveFactor",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9e4c3c21-f09e-4994-aa9a-1db01028f0d3",
   "metadata": {
    "name": "cell62",
    "collapsed": false
   },
   "source": "# 9. Results & Summary\nThis research underscores the significant impact of executive communication styles during earnings calls on firm performance. Proactive executives who anticipate market concerns and provide concise, on-topic responses foster transparency, aligning with investor expectations and driving superior returns. The findings demonstrate that firms with Efficient Communicators achieve statistically significant outperformance, while Total Redirectors suffer from diminished confidence and underperformance. These insights validate the critical role of strategic communication in shaping investor perceptions and influencing market outcomes.\n\nAdvanced analytical tools, such as vector embeddings and cosine similarity metrics, enable nuanced evaluations of executive-analyst interactions, revealing measurable performance effects across different communication styles. While large language models (LLMs) enhance feature extraction, challenges like forward-looking bias and inconsistency highlight the need for caution in time-sensitive tasks. Overall, the integration of proactive, clear, and relevant communication strategies remains paramount in fostering investor trust and maximizing financial success in a competitive marketplace."
  }
 ]
}