{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "d24wrwrpkn5p7ve6bync",
   "authorId": "4988802824334",
   "authorName": "HENRY.CHIANG@SPGLOBAL.COM",
   "authorEmail": "henry.chiang@spglobal.com",
   "sessionId": "1813c07c-6f1f-41cd-9018-c9ef3eaec978",
   "lastEditTime": 1739380444354
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "8b3e3fe0-c477-42c5-a3e3-554712bd9647",
   "metadata": {
    "language": "python",
    "name": "py_headline",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "import streamlit as st\nst.markdown(\"\"\"\n<div style=\"background-color: #000020; color: white; text-align: center; padding: 20px\">\n  <h1 style=\"margin: 0; color: white\"><b>Questioning the Answers: LLMs enter the Boardroom</b></h1>\n  <h2 style=\"margin: 0; color: white\"><b></b>Using Gen AI Tools to Harness Alpha from Earnings Calls</h2>\n  <h3 style=\"margin: 0; color: white\"><b>by S&P Global Market Intelligence's Quantitative Research & Solutions (QRS) Group</b></h3>\n</div>\n\"\"\", unsafe_allow_html=True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "df5cc4ff-46f3-4148-a12f-77f3328b1ad7",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "Read this QuickStart to setup an environment to run this notebook:"
  },
  {
   "cell_type": "markdown",
   "id": "04b2912a-e563-47a2-8731-7bba38772e76",
   "metadata": {
    "name": "md_1_overview",
    "collapsed": false
   },
   "source": "# 1. Overview\n\nEarnings calls play a pivotal role in shaping investor perceptions. The quality of communication between executives and analysts can significantly influence company performance. On-topic and proactive exeutives, who deliver proactive presentations, anticipate market queries, and provide clear, on-topic answers to analysts’ questions—consistently outperform their peers. Conversely, off-topic and reactive executives, who fail to address analysts’ key inquiries during presentations, and provide off-topic responses—significantly underperform.\n\nExecutives' ability to anticipate investor concerns and maintain a focused dialogue fosters confidence and strategic communication. In contrast, failing to provide clarity when analysts seek additional information can lead to misalignment and breakdowns in transparency. A long (short) portfolio of on-topic and proactive (off-topic and reactive) generates +515bps of annualized alpha.\n\nThis notebook serves as the blueprint for the research detailed in Quantitative Research & Solutions’ recent publication, [\"Questioninig the Answers: LLM's enter the Boardroom.\"](https://www.spglobal.com/market-intelligence/en/news-insights/research/questioning-the-answers-llms-enter-the-boardroom) It analyse executive on-topicness and proactiveness using the analysts questions, executives answers and LLM answers. This research harness alpha using LLM tools, including vector embeddings, vector cosine similarity, and the LLM quesiton answering."
  },
  {
   "cell_type": "markdown",
   "id": "fa040835-3299-4600-b06f-9a47ff3312f7",
   "metadata": {
    "name": "md_3_libraries",
    "collapsed": false
   },
   "source": "# 2. Libraries & User Inputs\nImport libraries required for the workflow\n\n## 2.1 Libraries"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "py_imports",
    "codeCollapsed": false,
    "collapsed": false
   },
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c4187b8f-34a3-402c-8c63-96623f676453",
   "metadata": {
    "name": "md_32_user_inputs",
    "collapsed": false
   },
   "source": "## 2.2 User Inputs\n\nThis research invloves the usage of an embedding model and a completion model, the default models were set to \"snowflake-arctic-embed-m\" for embedding and \"llama3.1-8b\" for completion. This user input section gives you the flexibility to chose your own model for the task."
  },
  {
   "cell_type": "code",
   "id": "fe9edb8d-b06e-4394-acd8-ba517c9b98d6",
   "metadata": {
    "language": "python",
    "name": "py_user_inputs",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Which of the two embedding functions we want to use\nsnf_embed_text_func = \"SNOWFLAKE.CORTEX.EMBED_TEXT_768\" \n\n# Which embedding model we want to use, see https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions#availability \n# for avalible embedding models in Snowflake\nembedding_model = \"snowflake-arctic-embed-m\" \n\n# Which LLM we want to use, see https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions#availability \n# for avalible LLMs in Snowflake\ncompletion_model = \"llama3.1-8b\" \n\n# Name of the databse created in the Setup Snowflake step\nsp_llm_qs_location = \"QRSLLM_POC_DB.QTA_SCHEMA\"\n\n# Name of the shared database created at the \"Request the S&P Global Market Intelligence QuickStart dataset\" step\nsp_qs_share_location = \"SPGLOBALXPRESSCLOUD_SPGMIQRS.XPRESSFEED\"",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5a4c140-634d-4a3d-9db3-bf2febbbbafc",
   "metadata": {
    "name": "md_2_datasets",
    "collapsed": false
   },
   "source": "# 3. Datasets\n\nThis notebook is using the Q&A pairing table from the S&P Global Q4 2024 Earnings Call on Feb 11, the data can be found in the Github directory."
  },
  {
   "cell_type": "code",
   "id": "75be4dc1-cd84-44ff-91ee-8ccedd7a0227",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false
   },
   "outputs": [],
   "source": "session.sql(f'''SELECT * FROM {sp_llm_qs_location}.SAMPLE_QA_PAIR ORDER BY ANSWERORDER ASC''')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2ddb0cf0-76c9-49f2-bab2-41de606b73ce",
   "metadata": {
    "name": "md_7_llm_ready_data",
    "collapsed": false
   },
   "source": "# 4. Working with the Data: LLM Ready Data\n\nUsing a LLM to answer analysts questions based only on the prepared remarks and the previous questions and answers will give an indication if executives are proactive.\n\n## 4.1 Using Snowflake Cortex AI\nWhen calling the Snowflake Cortex COMPLETE function, messages are organized into distinct roles—system, user, and assistant—to structure and guide interactions. Each role serves a specific purpose:\n\nSystem: Provides instructions that define the context or behavior of the model. It's like setting the rules or tone for the conversation. Example: \"You are a helpful assistant that answers questions about technology in a concise manner.\"\n\nUser: Represents the input or queries made by the person interacting with the model. These are the prompts or requests that the model responds to. Example: \"What is the purpose of the OpenAI API?\"\n\nAssistant: Reflects the model's response to the user's query, shaped by the system's instructions and the user's input. Example: \"The OpenAI API is designed to enable developers to integrate language models into their applications for tasks like answering questions, generating content, and more.\"\n\nIn our research, executive prepared remarks are labelled as assistant messages, analyst's questions as User messages and executive answers as Assistant messages"
  },
  {
   "cell_type": "markdown",
   "id": "c509c9a6-2350-4293-9acc-1fb5c540830e",
   "metadata": {
    "name": "md_73_collect_COMPLETE_responses",
    "collapsed": false
   },
   "source": "### 4.1.1 Apply LLM Completion\nWe apply the SNOWFLAKE.CORTEX.COMPLETE function on the prompt column using the model defined by `completion_model`and collect the LLM response."
  },
  {
   "cell_type": "code",
   "id": "30081e59-9940-4304-8ed3-62f2b8374696",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(f\"\"\"\n\n    select *,  SNOWFLAKE.CORTEX.COMPLETE('{completion_model}', prompt, {{'temperature': 0}}) as LLMAnswer \n    from {sp_llm_qs_location}.SAMPLE_QA_PAIR\n          \n\"\"\")\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0035b140-240c-45bd-8d0a-e51764d0a3eb",
   "metadata": {
    "name": "md_732_clean_up_LLM_responses",
    "collapsed": false
   },
   "source": "### 4.1.2 Clean Up LLM Response\n\nExtract only the actual message from the LLM from the responses"
  },
  {
   "cell_type": "code",
   "id": "62333d10-d5e7-48fa-8e0d-0aa93fb66e10",
   "metadata": {
    "language": "python",
    "name": "py_extract_message"
   },
   "outputs": [],
   "source": "df = session.sql(f\"\"\"\n\n    select \n        callDate, tradingItemId, transcriptId, headline, \n        questionTranscriptPersonName, questionTranscriptPersonId, questionProId, answerTranscriptPersonName, answerTranscriptPersonId, answerProId,\n        questionTranscriptComponentId, answerTranscriptComponentId, question, answer,\n        REPLACE(LLMANSWER: \"choices\"[0]: \"messages\", '\"', '') as cleanLLMAnswer \n    from {sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer\n          \n\"\"\")\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer_Clean\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb29bb53-5a68-4d00-978a-6302b1eb16a8",
   "metadata": {
    "name": "md_74_summarize_text",
    "collapsed": false
   },
   "source": "## 4.2 Summarize Text\n\nUse the Snowflake Cortex Summarize function to summarize the question, answer and LLM answer"
  },
  {
   "cell_type": "code",
   "id": "6d5c15c2-52f1-4dc0-9a7d-2ea683ec2391",
   "metadata": {
    "language": "python",
    "name": "py_summarize",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(f\"\"\"\n\n    select \n        *, \n        SNOWFLAKE.CORTEX.SUMMARIZE(question) as summarizeQuestion,\n        SNOWFLAKE.CORTEX.SUMMARIZE(answer) as summarizeAnswer,\n        SNOWFLAKE.CORTEX.SUMMARIZE(cleanLLMAnswer) as summarizeCleanLLMAnswer,\n    from {sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer_Clean\n          \n\"\"\")\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer_Summarize\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cde8c8fb-317d-40ec-b17b-a7efc118fc78",
   "metadata": {
    "name": "md_8_factor_construction",
    "collapsed": false
   },
   "source": "# 5. Working with the Data: Factor Construction\n## 5.1 Executive On/Off Topic Factor\nWhen an executive answer is semantically similar (dissimilar) to the analyst’s question, it suggests that the answer uses language and concepts similar to (different from) the analyst question, indicating it is on-topic (off-topic). To determine semantic closeness, we vector-embed the question-and-answer texts and calculate a cosine similarity score between the two vectors.\n\n### 5.1.1 Question vs Executive Answer Cosine Similarity"
  },
  {
   "cell_type": "code",
   "id": "ffc83173-e945-42e1-a8ce-3fe2785bd834",
   "metadata": {
    "language": "python",
    "name": "py_q_v_a_cosine_sim",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n\n    with vec as(\n    select *\n        , {snf_embed_text_func}('{embedding_model}', summarizeQuestion) as questionVec\n        , {snf_embed_text_func}('{embedding_model}', summarizeAnswer) as answerVec \n    from {sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer_Summarize\n    )\n    select *, VECTOR_COSINE_SIMILARITY(questionVec, answerVec) as execOnOffTopicFactor from vec \n               \n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_execOnOffTopicFactor\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "38be14f8-7a72-4aab-984c-43aa3e76ff97",
   "metadata": {
    "name": "md_812_mean_on_off_topic",
    "collapsed": false
   },
   "source": "### 5.1.2 Transcript Mean Executive On/Off Topic Factor\nCosine similarity scores are averaged at the transcript level. A high (low) Cosine Similarity Score indicates an On (Off) Topic Executive.\n\n"
  },
  {
   "cell_type": "code",
   "id": "9c2f2ed4-20eb-4ff6-a527-05c9362b066f",
   "metadata": {
    "language": "sql",
    "name": "sql_mean_on_off_topic"
   },
   "outputs": [],
   "source": "select avg(execOnOffTopicFactor) as transcriptLevelExecOnOffTopicFactor \nfrom {{sp_llm_qs_location}}.TranscriptComponents_execOnOffTopicFactor",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "916210b3-8d62-4bac-9a1a-13fbc0d08ffc",
   "metadata": {
    "name": "md_82_executive_pro_re_factor",
    "collapsed": false
   },
   "source": "## 8.2 Executive Proactive/Reactive Factor\n### 8.2.1 Question vs LLM Answer Cosine Similarity\nSince the LLM answers only within the context of information provided in the prepared remarks, a high (low) cosine similarity score indicates that the LLM answers are semantically similar (dissimilar) the questions, reflecting the executives are proactive (reactive)."
  },
  {
   "cell_type": "code",
   "id": "06d679e9-5849-44cd-b73a-595e4a9df160",
   "metadata": {
    "language": "python",
    "name": "py_q_llmA_cosine_sim"
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n\n    with vec as(\n    select \n        *, \n        {snf_embed_text_func}('{embedding_model}', summarizeQuestion) as questionVec, \n        {snf_embed_text_func}('{embedding_model}', summarizeCleanLLMAnswer) as LLMAnswerVec \n    from {sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer_Summarize\n    )\n    select *, VECTOR_COSINE_SIMILARITY(questionVec, LLMAnswerVec) as execProactiveReactiveFactor from vec \n               \n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_execProactiveReactiveFactor\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5999994a-81e2-428f-ab24-4a5eeb72e150",
   "metadata": {
    "name": "md_822_mean_pro_re_factor",
    "collapsed": false
   },
   "source": "### 8.2.2 Transcript Mean Executive Proactive/Reactive Factor\nSimilar to the construction of the Executive On/Off Topic factor, both the LLM answers and questions are summarized, vector-embedded and cosine similarity scores are averaged at the transcript level."
  },
  {
   "cell_type": "code",
   "id": "79c48dfb-ca72-41ba-af86-d0f5975d6c48",
   "metadata": {
    "language": "sql",
    "name": "sql_mean_pro_re_factor"
   },
   "outputs": [],
   "source": "select avg(execProactiveReactiveFactor) as transcriptLevelexecProactiveReactiveFactor \nfrom {{sp_llm_qs_location}}.TranscriptComponents_execProactiveReactiveFactor",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9e4c3c21-f09e-4994-aa9a-1db01028f0d3",
   "metadata": {
    "name": "md_9_result_summary",
    "collapsed": false
   },
   "source": "# 9. Results & Summary\nThis research underscores the significant impact of executive communication styles during earnings calls on firm performance. Proactive executives who anticipate market concerns and provide concise, on-topic responses foster transparency, aligning with investor expectations and driving superior returns. The findings demonstrate that firms with Efficient Communicators achieve statistically significant outperformance, while Total Redirectors suffer from diminished confidence and underperformance. These insights validate the critical role of strategic communication in shaping investor perceptions and influencing market outcomes.\n\nAdvanced analytical tools, such as vector embeddings and cosine similarity metrics, enable nuanced evaluations of executive-analyst interactions, revealing measurable performance effects across different communication styles. While large language models (LLMs) enhance feature extraction, challenges like forward-looking bias and inconsistency highlight the need for caution in time-sensitive tasks. Overall, the integration of proactive, clear, and relevant communication strategies remains paramount in fostering investor trust and maximizing financial success in a competitive marketplace."
  }
 ]
}